{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8670</td>\n",
       "      <td>M</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8913</td>\n",
       "      <td>B</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8915</td>\n",
       "      <td>B</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9047</td>\n",
       "      <td>B</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85715</td>\n",
       "      <td>M</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0   8670         M        15.46         19.48          101.70      748.9   \n",
       "1   8913         B        12.89         13.12           81.89      515.9   \n",
       "2   8915         B        14.96         19.10           97.03      687.3   \n",
       "3   9047         B        12.94         16.17           83.18      507.6   \n",
       "4  85715         M        13.17         18.66           85.98      534.6   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.10920           0.12230         0.14660              0.08087   \n",
       "1          0.06955           0.03729         0.02260              0.01171   \n",
       "2          0.08992           0.09823         0.05940              0.04819   \n",
       "3          0.09879           0.08836         0.03296              0.02390   \n",
       "4          0.11580           0.12310         0.12260              0.07340   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         19.26          26.00           124.90      1156.0   \n",
       "1  ...         13.62          15.54            87.40       577.0   \n",
       "2  ...         16.25          26.19           109.10       809.8   \n",
       "3  ...         13.86          23.02            89.69       580.9   \n",
       "4  ...         15.67          27.95           102.80       759.4   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0           0.15460             0.2394           0.3791               0.15140   \n",
       "1           0.09616             0.1147           0.1186               0.05366   \n",
       "2           0.13130             0.3030           0.1804               0.14890   \n",
       "3           0.11720             0.1958           0.1810               0.08388   \n",
       "4           0.17860             0.4166           0.5006               0.20880   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.2837                  0.08019  \n",
       "1          0.2309                  0.06915  \n",
       "2          0.2962                  0.08472  \n",
       "3          0.3297                  0.07834  \n",
       "4          0.3900                  0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.read_csv(os.path.join(\"data.csv\"))\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.loc[(cancer_df.diagnosis == 'B'),'diagnosis']='Benign'\n",
    "cancer_df.loc[(cancer_df.diagnosis == 'M'),'diagnosis']='Malignant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.rename(columns = {'id':'Paitent ID', 'diagnosis':'Diagnosis'\n",
    "                            , 'radius_mean':'Radius (Mean)', 'texture_mean':'Texture (Mean)', 'perimeter_mean':'Perimeter (Mean)'\n",
    "                           , 'area_mean':'Area (Mean)', 'smoothness_mean':'Smoothness (Mean)', 'compactness_mean':'Compactness (Mean)', 'concavity_mean':'Concavity (Mean)', 'concave points_mean':'Concave Points (Mean)'\n",
    "                           , 'symmetry_mean':'Symmetry (Mean)', 'fractal_dimension_mean':'Fractal Dimension (Mean)'\n",
    "                            , 'radius_se':'Radius (Standard Error)', 'texture_se':'Texture (Standard Error)', 'perimeter_se':'Perimeter (Standard Error)'\n",
    "                            , 'area_se':'Area (Standard Error)', 'smoothness_se':'Smoothness (Standard Error)', 'compactness_se':'Compactness (Standard Error)', 'concavity_se':'Concavity (Standard Error)', 'concave points_se':'Concave Points (Standard Error)'\n",
    "                            , 'symmetry_se':'Symmetry (Standard Error)', 'fractal_dimension_se':'Fractal Dimension (Standard Error)'\n",
    "                            , 'radius_worst':'Radius (Worst)', 'texture_worst':'Texture (Worst)', 'perimeter_worst':'Perimeter (Worst)'\n",
    "                           , 'area_worst':'Area (Worst)', 'smoothness_worst':'Smoothness (Worst)', 'compactness_worst':'Compactness (Worst)', 'concavity_worst':'Concavity (Worst)', 'concave points_worst':'Concave Points (Worst)'\n",
    "                           , 'symmetry_worst':'Symmetry (Worst)', 'fractal_dimension_worst':'Fractal Dimension (Worst)'\n",
    "                           }, inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.to_csv(r\"C:\\Users\\minam\\Documents\\BOOTCAMP\\PROJECT_3\\Final-Project-master\\Cancer_Data.csv\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31) (569,)\n"
     ]
    }
   ],
   "source": [
    "X = cancer_df.drop(\"Diagnosis\", axis=1)\n",
    "y = cancer_df[\"Diagnosis\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6431924882629108\n",
      "Testing Data Score: 0.5804195804195804\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign']\n",
      "First 10 Actual labels: ['Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction     Actual\n",
       "0       Benign  Malignant\n",
       "1       Benign  Malignant\n",
       "2       Benign     Benign\n",
       "3       Benign     Benign\n",
       "4       Benign     Benign\n",
       "..         ...        ...\n",
       "138     Benign  Malignant\n",
       "139     Benign     Benign\n",
       "140     Benign     Benign\n",
       "141     Benign     Benign\n",
       "142     Benign     Benign\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cancer_df[\"Diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>Symmetry (Mean)</th>\n",
       "      <th>Fractal Dimension (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.05852</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.06200</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.06777</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Radius (Mean)  Texture (Mean)  Perimeter (Mean)  Area (Mean)  \\\n",
       "0          15.46           19.48            101.70        748.9   \n",
       "1          12.89           13.12             81.89        515.9   \n",
       "2          14.96           19.10             97.03        687.3   \n",
       "3          12.94           16.17             83.18        507.6   \n",
       "4          13.17           18.66             85.98        534.6   \n",
       "\n",
       "   Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0            0.10920             0.12230           0.14660   \n",
       "1            0.06955             0.03729           0.02260   \n",
       "2            0.08992             0.09823           0.05940   \n",
       "3            0.09879             0.08836           0.03296   \n",
       "4            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  Symmetry (Mean)  Fractal Dimension (Mean)  ...  \\\n",
       "0                0.08087           0.1931                   0.05796  ...   \n",
       "1                0.01171           0.1337                   0.05581  ...   \n",
       "2                0.04819           0.1879                   0.05852  ...   \n",
       "3                0.02390           0.1735                   0.06200  ...   \n",
       "4                0.07340           0.2128                   0.06777  ...   \n",
       "\n",
       "   Radius (Worst)  Texture (Worst)  Perimeter (Worst)  Area (Worst)  \\\n",
       "0           19.26            26.00             124.90        1156.0   \n",
       "1           13.62            15.54              87.40         577.0   \n",
       "2           16.25            26.19             109.10         809.8   \n",
       "3           13.86            23.02              89.69         580.9   \n",
       "4           15.67            27.95             102.80         759.4   \n",
       "\n",
       "   Smoothness (Worst)  Compactness (Worst)  Concavity (Worst)  \\\n",
       "0             0.15460               0.2394             0.3791   \n",
       "1             0.09616               0.1147             0.1186   \n",
       "2             0.13130               0.3030             0.1804   \n",
       "3             0.11720               0.1958             0.1810   \n",
       "4             0.17860               0.4166             0.5006   \n",
       "\n",
       "   Concave Points (Worst)  Symmetry (Worst)  Fractal Dimension (Worst)  \n",
       "0                 0.15140            0.2837                    0.08019  \n",
       "1                 0.05366            0.2309                    0.06915  \n",
       "2                 0.14890            0.2962                    0.08472  \n",
       "3                 0.08388            0.3297                    0.07834  \n",
       "4                 0.20880            0.3900                    0.11790  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = cancer_df.drop(\"Diagnosis\", axis =1)\n",
    "X = X_df.drop(\"Paitent ID\", axis =1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.916\n",
      "k: 3, Train/Test Score: 0.958/0.923\n",
      "k: 5, Train/Test Score: 0.944/0.930\n",
      "k: 7, Train/Test Score: 0.944/0.916\n",
      "k: 9, Train/Test Score: 0.944/0.916\n",
      "k: 11, Train/Test Score: 0.946/0.923\n",
      "k: 13, Train/Test Score: 0.944/0.923\n",
      "k: 15, Train/Test Score: 0.937/0.930\n",
      "k: 17, Train/Test Score: 0.937/0.930\n",
      "k: 19, Train/Test Score: 0.937/0.930\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=13 Test Acc: 0.923\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=13 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916083916083916"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train_categorical)\n",
    "clf.score(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train_categorical)\n",
    "rf.score(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.13837865328722904, 'Area (Worst)'),\n",
       " (0.12690615528139007, 'Concave Points (Worst)'),\n",
       " (0.1234303439572677, 'Radius (Worst)'),\n",
       " (0.10909701829741111, 'Perimeter (Worst)'),\n",
       " (0.0799982747968158, 'Concave Points (Mean)'),\n",
       " (0.0516788583487961, 'Concavity (Mean)'),\n",
       " (0.04723928149908427, 'Area (Standard Error)'),\n",
       " (0.045727391619860364, 'Area (Mean)'),\n",
       " (0.039738114472495194, 'Perimeter (Mean)'),\n",
       " (0.0346178965165232, 'Radius (Mean)'),\n",
       " (0.031326032663252845, 'Concavity (Worst)'),\n",
       " (0.02373250008745949, 'Compactness (Worst)'),\n",
       " (0.021871842514110347, 'Radius (Standard Error)'),\n",
       " (0.015100201030719749, 'Compactness (Mean)'),\n",
       " (0.014604446027001897, 'Smoothness (Worst)'),\n",
       " (0.013157155911557365, 'Texture (Worst)'),\n",
       " (0.011321515647313549, 'Texture (Mean)'),\n",
       " (0.010803730374495009, 'Symmetry (Worst)'),\n",
       " (0.009077780882596602, 'Fractal Dimension (Worst)'),\n",
       " (0.006312212591255439, 'Smoothness (Mean)'),\n",
       " (0.00571206304467743, 'Concave Points (Standard Error)'),\n",
       " (0.005229981430818638, 'Perimeter (Standard Error)'),\n",
       " (0.005180342110155227, 'Symmetry (Mean)'),\n",
       " (0.005059074769743886, 'Fractal Dimension (Standard Error)'),\n",
       " (0.0047374553536652, 'Compactness (Standard Error)'),\n",
       " (0.004660204551829628, 'Texture (Standard Error)'),\n",
       " (0.0041021196078628724, 'Fractal Dimension (Mean)'),\n",
       " (0.0040161529174858246, 'Symmetry (Standard Error)'),\n",
       " (0.0036317636953393526, 'Concavity (Standard Error)'),\n",
       " (0.003551436711786794, 'Smoothness (Standard Error)')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build lists for mean and SEM Value for radius and permiter values\n",
    "#Radius (Mean)\n",
    "radius_means = cancer_df.loc[:, ['Radius (Mean)']]\n",
    "radius_means = radius_means['Radius (Mean)']\n",
    "\n",
    "#Perimeter (Worst)\n",
    "perimeter_means = cancer_df.loc[:, ['Perimeter (Worst)']]\n",
    "perimeter_means = perimeter_means['Perimeter (Worst)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the Plot (with Error Bars)\n",
    "#Min/Max values for volume to determine limits on plot chart\n",
    "min_volume = cancer_df.min()['Radius (Mean)']\n",
    "max_volume = cancer_df.max()['Radius (Mean)']\n",
    "max_yvolume = cancer_df.max()['Perimeter (Worst)']\n",
    "\n",
    "#create additional white space on plot chart\n",
    "min_volume = min_volume - 1\n",
    "max_volume = max_volume + 1\n",
    "max_yvolume = max_yvolume + 2\n",
    "#Limits, background grid, title, labels\n",
    "plt.grid(True)\n",
    "\n",
    "plt.ylabel(\"Perimeter (Worst)\")\n",
    "plt.xlabel(\"Radius (Mean)\")\n",
    "plt.title(\"Perimeter v Radius\")\n",
    "plt.scatter(radius_means, perimeter_means)\n",
    "plt.legend(frameon=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      1.00      0.98        80\n",
      "    positive       1.00      0.94      0.97        63\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.98      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.930, total=   1.2s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.929, total=   5.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.976, total=   1.7s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.918, total=   3.2s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.953, total=   2.8s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.930, total=   1.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.929, total=   3.3s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.976, total=   1.7s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.918, total=   3.2s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.953, total=   2.8s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.930, total=   1.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.929, total=   3.2s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.976, total=   1.7s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.918, total=   3.2s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.953, total=   2.8s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.965, total=   1.2s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.941, total=   7.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.976, total=   5.3s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.918, total=   4.8s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.976, total=   8.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.965, total=   1.2s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.941, total=   6.9s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.976, total=   5.3s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.918, total=   4.8s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.976, total=   8.6s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.965, total=   1.2s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.941, total=   7.0s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.976, total=   5.3s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.918, total=   4.8s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.976, total=   8.5s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.930, total=   5.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.953, total=   6.6s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=1.000, total=   2.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.906, total=   2.3s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.941, total=   5.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.930, total=   2.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.953, total=   3.5s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=1.000, total=   1.9s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.906, total=   2.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.941, total=   5.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.930, total=   2.3s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.953, total=   3.9s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=1.000, total=   2.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.906, total=   2.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.941, total=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='linear', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955376196990424\n"
     ]
    }
   ],
   "source": [
    "# List the best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        blue       0.96      1.00      0.98        80\n",
      "         red       1.00      0.95      0.98        63\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"blue\", \"red\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Reformat data\n",
    "data = cancer_df.values\n",
    "X = data[:, 2:35]\n",
    "y = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = 30\n",
    "number_hidden_nodes = 4\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 2\n",
    "model.add(Dense(units=6, activation='relu', input_dim=2))\n",
    "model.add(Dense(units=6, activation='relu'))\n",
    "model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 124       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 210\n",
      "Trainable params: 210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "14/14 - 0s - loss: 0.7876 - accuracy: 0.1479\n",
      "Epoch 2/1000\n",
      "14/14 - 0s - loss: 0.7430 - accuracy: 0.2277\n",
      "Epoch 3/1000\n",
      "14/14 - 0s - loss: 0.7084 - accuracy: 0.3709\n",
      "Epoch 4/1000\n",
      "14/14 - 0s - loss: 0.6826 - accuracy: 0.5634\n",
      "Epoch 5/1000\n",
      "14/14 - 0s - loss: 0.6605 - accuracy: 0.6315\n",
      "Epoch 6/1000\n",
      "14/14 - 0s - loss: 0.6359 - accuracy: 0.6502\n",
      "Epoch 7/1000\n",
      "14/14 - 0s - loss: 0.6040 - accuracy: 0.6502\n",
      "Epoch 8/1000\n",
      "14/14 - 0s - loss: 0.5606 - accuracy: 0.6502\n",
      "Epoch 9/1000\n",
      "14/14 - 0s - loss: 0.5075 - accuracy: 0.6502\n",
      "Epoch 10/1000\n",
      "14/14 - 0s - loss: 0.4579 - accuracy: 0.6502\n",
      "Epoch 11/1000\n",
      "14/14 - 0s - loss: 0.4153 - accuracy: 0.6502\n",
      "Epoch 12/1000\n",
      "14/14 - 0s - loss: 0.3836 - accuracy: 0.6502\n",
      "Epoch 13/1000\n",
      "14/14 - 0s - loss: 0.3611 - accuracy: 0.6502\n",
      "Epoch 14/1000\n",
      "14/14 - 0s - loss: 0.3425 - accuracy: 0.6502\n",
      "Epoch 15/1000\n",
      "14/14 - 0s - loss: 0.3271 - accuracy: 0.6502\n",
      "Epoch 16/1000\n",
      "14/14 - 0s - loss: 0.3148 - accuracy: 0.6972\n",
      "Epoch 17/1000\n",
      "14/14 - 0s - loss: 0.3058 - accuracy: 0.9484\n",
      "Epoch 18/1000\n",
      "14/14 - 0s - loss: 0.2977 - accuracy: 0.9601\n",
      "Epoch 19/1000\n",
      "14/14 - 0s - loss: 0.2910 - accuracy: 0.9601\n",
      "Epoch 20/1000\n",
      "14/14 - 0s - loss: 0.2840 - accuracy: 0.9601\n",
      "Epoch 21/1000\n",
      "14/14 - 0s - loss: 0.2782 - accuracy: 0.9601\n",
      "Epoch 22/1000\n",
      "14/14 - 0s - loss: 0.2727 - accuracy: 0.9648\n",
      "Epoch 23/1000\n",
      "14/14 - 0s - loss: 0.2675 - accuracy: 0.9671\n",
      "Epoch 24/1000\n",
      "14/14 - 0s - loss: 0.2624 - accuracy: 0.9695\n",
      "Epoch 25/1000\n",
      "14/14 - 0s - loss: 0.2574 - accuracy: 0.9695\n",
      "Epoch 26/1000\n",
      "14/14 - 0s - loss: 0.2527 - accuracy: 0.9718\n",
      "Epoch 27/1000\n",
      "14/14 - 0s - loss: 0.2480 - accuracy: 0.9765\n",
      "Epoch 28/1000\n",
      "14/14 - 0s - loss: 0.2436 - accuracy: 0.9765\n",
      "Epoch 29/1000\n",
      "14/14 - 0s - loss: 0.2400 - accuracy: 0.9765\n",
      "Epoch 30/1000\n",
      "14/14 - 0s - loss: 0.2358 - accuracy: 0.9765\n",
      "Epoch 31/1000\n",
      "14/14 - 0s - loss: 0.2318 - accuracy: 0.9742\n",
      "Epoch 32/1000\n",
      "14/14 - 0s - loss: 0.2281 - accuracy: 0.9765\n",
      "Epoch 33/1000\n",
      "14/14 - 0s - loss: 0.2245 - accuracy: 0.9789\n",
      "Epoch 34/1000\n",
      "14/14 - 0s - loss: 0.2210 - accuracy: 0.9789\n",
      "Epoch 35/1000\n",
      "14/14 - 0s - loss: 0.2173 - accuracy: 0.9789\n",
      "Epoch 36/1000\n",
      "14/14 - 0s - loss: 0.2139 - accuracy: 0.9789\n",
      "Epoch 37/1000\n",
      "14/14 - 0s - loss: 0.2108 - accuracy: 0.9789\n",
      "Epoch 38/1000\n",
      "14/14 - 0s - loss: 0.2076 - accuracy: 0.9812\n",
      "Epoch 39/1000\n",
      "14/14 - 0s - loss: 0.2043 - accuracy: 0.9812\n",
      "Epoch 40/1000\n",
      "14/14 - 0s - loss: 0.2014 - accuracy: 0.9812\n",
      "Epoch 41/1000\n",
      "14/14 - 0s - loss: 0.1985 - accuracy: 0.9789\n",
      "Epoch 42/1000\n",
      "14/14 - 0s - loss: 0.1955 - accuracy: 0.9836\n",
      "Epoch 43/1000\n",
      "14/14 - 0s - loss: 0.1929 - accuracy: 0.9836\n",
      "Epoch 44/1000\n",
      "14/14 - 0s - loss: 0.1901 - accuracy: 0.9836\n",
      "Epoch 45/1000\n",
      "14/14 - 0s - loss: 0.1878 - accuracy: 0.9836\n",
      "Epoch 46/1000\n",
      "14/14 - 0s - loss: 0.1847 - accuracy: 0.9859\n",
      "Epoch 47/1000\n",
      "14/14 - 0s - loss: 0.1822 - accuracy: 0.9859\n",
      "Epoch 48/1000\n",
      "14/14 - 0s - loss: 0.1794 - accuracy: 0.9859\n",
      "Epoch 49/1000\n",
      "14/14 - 0s - loss: 0.1770 - accuracy: 0.9859\n",
      "Epoch 50/1000\n",
      "14/14 - 0s - loss: 0.1743 - accuracy: 0.9859\n",
      "Epoch 51/1000\n",
      "14/14 - 0s - loss: 0.1720 - accuracy: 0.9859\n",
      "Epoch 52/1000\n",
      "14/14 - 0s - loss: 0.1696 - accuracy: 0.9859\n",
      "Epoch 53/1000\n",
      "14/14 - 0s - loss: 0.1674 - accuracy: 0.9859\n",
      "Epoch 54/1000\n",
      "14/14 - 0s - loss: 0.1651 - accuracy: 0.9859\n",
      "Epoch 55/1000\n",
      "14/14 - 0s - loss: 0.1629 - accuracy: 0.9859\n",
      "Epoch 56/1000\n",
      "14/14 - 0s - loss: 0.1608 - accuracy: 0.9859\n",
      "Epoch 57/1000\n",
      "14/14 - 0s - loss: 0.1587 - accuracy: 0.9859\n",
      "Epoch 58/1000\n",
      "14/14 - 0s - loss: 0.1571 - accuracy: 0.9859\n",
      "Epoch 59/1000\n",
      "14/14 - 0s - loss: 0.1547 - accuracy: 0.9859\n",
      "Epoch 60/1000\n",
      "14/14 - 0s - loss: 0.1528 - accuracy: 0.9859\n",
      "Epoch 61/1000\n",
      "14/14 - 0s - loss: 0.1508 - accuracy: 0.9859\n",
      "Epoch 62/1000\n",
      "14/14 - 0s - loss: 0.1488 - accuracy: 0.9859\n",
      "Epoch 63/1000\n",
      "14/14 - 0s - loss: 0.1467 - accuracy: 0.9859\n",
      "Epoch 64/1000\n",
      "14/14 - 0s - loss: 0.1450 - accuracy: 0.9859\n",
      "Epoch 65/1000\n",
      "14/14 - 0s - loss: 0.1429 - accuracy: 0.9859\n",
      "Epoch 66/1000\n",
      "14/14 - 0s - loss: 0.1409 - accuracy: 0.9859\n",
      "Epoch 67/1000\n",
      "14/14 - 0s - loss: 0.1387 - accuracy: 0.9883\n",
      "Epoch 68/1000\n",
      "14/14 - 0s - loss: 0.1368 - accuracy: 0.9883\n",
      "Epoch 69/1000\n",
      "14/14 - 0s - loss: 0.1351 - accuracy: 0.9883\n",
      "Epoch 70/1000\n",
      "14/14 - 0s - loss: 0.1332 - accuracy: 0.9883\n",
      "Epoch 71/1000\n",
      "14/14 - 0s - loss: 0.1316 - accuracy: 0.9883\n",
      "Epoch 72/1000\n",
      "14/14 - 0s - loss: 0.1295 - accuracy: 0.9883\n",
      "Epoch 73/1000\n",
      "14/14 - 0s - loss: 0.1280 - accuracy: 0.9883\n",
      "Epoch 74/1000\n",
      "14/14 - 0s - loss: 0.1260 - accuracy: 0.9883\n",
      "Epoch 75/1000\n",
      "14/14 - 0s - loss: 0.1243 - accuracy: 0.9883\n",
      "Epoch 76/1000\n",
      "14/14 - 0s - loss: 0.1228 - accuracy: 0.9883\n",
      "Epoch 77/1000\n",
      "14/14 - 0s - loss: 0.1215 - accuracy: 0.9883\n",
      "Epoch 78/1000\n",
      "14/14 - 0s - loss: 0.1195 - accuracy: 0.9883\n",
      "Epoch 79/1000\n",
      "14/14 - 0s - loss: 0.1182 - accuracy: 0.9883\n",
      "Epoch 80/1000\n",
      "14/14 - 0s - loss: 0.1165 - accuracy: 0.9883\n",
      "Epoch 81/1000\n",
      "14/14 - 0s - loss: 0.1152 - accuracy: 0.9883\n",
      "Epoch 82/1000\n",
      "14/14 - 0s - loss: 0.1134 - accuracy: 0.9883\n",
      "Epoch 83/1000\n",
      "14/14 - 0s - loss: 0.1120 - accuracy: 0.9883\n",
      "Epoch 84/1000\n",
      "14/14 - 0s - loss: 0.1103 - accuracy: 0.9883\n",
      "Epoch 85/1000\n",
      "14/14 - 0s - loss: 0.1090 - accuracy: 0.9883\n",
      "Epoch 86/1000\n",
      "14/14 - 0s - loss: 0.1076 - accuracy: 0.9883\n",
      "Epoch 87/1000\n",
      "14/14 - 0s - loss: 0.1060 - accuracy: 0.9883\n",
      "Epoch 88/1000\n",
      "14/14 - 0s - loss: 0.1044 - accuracy: 0.9883\n",
      "Epoch 89/1000\n",
      "14/14 - 0s - loss: 0.1033 - accuracy: 0.9883\n",
      "Epoch 90/1000\n",
      "14/14 - 0s - loss: 0.1014 - accuracy: 0.9883\n",
      "Epoch 91/1000\n",
      "14/14 - 0s - loss: 0.0998 - accuracy: 0.9883\n",
      "Epoch 92/1000\n",
      "14/14 - 0s - loss: 0.0985 - accuracy: 0.9883\n",
      "Epoch 93/1000\n",
      "14/14 - 0s - loss: 0.0974 - accuracy: 0.9883\n",
      "Epoch 94/1000\n",
      "14/14 - 0s - loss: 0.0957 - accuracy: 0.9883\n",
      "Epoch 95/1000\n",
      "14/14 - 0s - loss: 0.0942 - accuracy: 0.9883\n",
      "Epoch 96/1000\n",
      "14/14 - 0s - loss: 0.0930 - accuracy: 0.9883\n",
      "Epoch 97/1000\n",
      "14/14 - 0s - loss: 0.0917 - accuracy: 0.9883\n",
      "Epoch 98/1000\n",
      "14/14 - 0s - loss: 0.0905 - accuracy: 0.9883\n",
      "Epoch 99/1000\n",
      "14/14 - 0s - loss: 0.0891 - accuracy: 0.9906\n",
      "Epoch 100/1000\n",
      "14/14 - 0s - loss: 0.0877 - accuracy: 0.9906\n",
      "Epoch 101/1000\n",
      "14/14 - 0s - loss: 0.0865 - accuracy: 0.9906\n",
      "Epoch 102/1000\n",
      "14/14 - 0s - loss: 0.0853 - accuracy: 0.9906\n",
      "Epoch 103/1000\n",
      "14/14 - 0s - loss: 0.0839 - accuracy: 0.9906\n",
      "Epoch 104/1000\n",
      "14/14 - 0s - loss: 0.0826 - accuracy: 0.9906\n",
      "Epoch 105/1000\n",
      "14/14 - 0s - loss: 0.0814 - accuracy: 0.9906\n",
      "Epoch 106/1000\n",
      "14/14 - 0s - loss: 0.0802 - accuracy: 0.9906\n",
      "Epoch 107/1000\n",
      "14/14 - 0s - loss: 0.0790 - accuracy: 0.9906\n",
      "Epoch 108/1000\n",
      "14/14 - 0s - loss: 0.0779 - accuracy: 0.9906\n",
      "Epoch 109/1000\n",
      "14/14 - 0s - loss: 0.0765 - accuracy: 0.9906\n",
      "Epoch 110/1000\n",
      "14/14 - 0s - loss: 0.0756 - accuracy: 0.9906\n",
      "Epoch 111/1000\n",
      "14/14 - 0s - loss: 0.0743 - accuracy: 0.9906\n",
      "Epoch 112/1000\n",
      "14/14 - 0s - loss: 0.0730 - accuracy: 0.9906\n",
      "Epoch 113/1000\n",
      "14/14 - 0s - loss: 0.0719 - accuracy: 0.9906\n",
      "Epoch 114/1000\n",
      "14/14 - 0s - loss: 0.0708 - accuracy: 0.9906\n",
      "Epoch 115/1000\n",
      "14/14 - 0s - loss: 0.0704 - accuracy: 0.9906\n",
      "Epoch 116/1000\n",
      "14/14 - 0s - loss: 0.0686 - accuracy: 0.9906\n",
      "Epoch 117/1000\n",
      "14/14 - 0s - loss: 0.0676 - accuracy: 0.9906\n",
      "Epoch 118/1000\n",
      "14/14 - 0s - loss: 0.0668 - accuracy: 0.9906\n",
      "Epoch 119/1000\n",
      "14/14 - 0s - loss: 0.0656 - accuracy: 0.9906\n",
      "Epoch 120/1000\n",
      "14/14 - 0s - loss: 0.0648 - accuracy: 0.9906\n",
      "Epoch 121/1000\n",
      "14/14 - 0s - loss: 0.0635 - accuracy: 0.9906\n",
      "Epoch 122/1000\n",
      "14/14 - 0s - loss: 0.0624 - accuracy: 0.9906\n",
      "Epoch 123/1000\n",
      "14/14 - 0s - loss: 0.0615 - accuracy: 0.9906\n",
      "Epoch 124/1000\n",
      "14/14 - 0s - loss: 0.0607 - accuracy: 0.9906\n",
      "Epoch 125/1000\n",
      "14/14 - 0s - loss: 0.0597 - accuracy: 0.9906\n",
      "Epoch 126/1000\n",
      "14/14 - 0s - loss: 0.0590 - accuracy: 0.9906\n",
      "Epoch 127/1000\n",
      "14/14 - 0s - loss: 0.0578 - accuracy: 0.9906\n",
      "Epoch 128/1000\n",
      "14/14 - 0s - loss: 0.0569 - accuracy: 0.9906\n",
      "Epoch 129/1000\n",
      "14/14 - 0s - loss: 0.0559 - accuracy: 0.9930\n",
      "Epoch 130/1000\n",
      "14/14 - 0s - loss: 0.0553 - accuracy: 0.9930\n",
      "Epoch 131/1000\n",
      "14/14 - 0s - loss: 0.0547 - accuracy: 0.9953\n",
      "Epoch 132/1000\n",
      "14/14 - 0s - loss: 0.0537 - accuracy: 0.9953\n",
      "Epoch 133/1000\n",
      "14/14 - 0s - loss: 0.0525 - accuracy: 0.9977\n",
      "Epoch 134/1000\n",
      "14/14 - 0s - loss: 0.0518 - accuracy: 0.9953\n",
      "Epoch 135/1000\n",
      "14/14 - 0s - loss: 0.0509 - accuracy: 0.9953\n",
      "Epoch 136/1000\n",
      "14/14 - 0s - loss: 0.0498 - accuracy: 0.9953\n",
      "Epoch 137/1000\n",
      "14/14 - 0s - loss: 0.0489 - accuracy: 0.9953\n",
      "Epoch 138/1000\n",
      "14/14 - 0s - loss: 0.0481 - accuracy: 0.9953\n",
      "Epoch 139/1000\n",
      "14/14 - 0s - loss: 0.0476 - accuracy: 0.9953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1000\n",
      "14/14 - 0s - loss: 0.0466 - accuracy: 0.9977\n",
      "Epoch 141/1000\n",
      "14/14 - 0s - loss: 0.0459 - accuracy: 0.9977\n",
      "Epoch 142/1000\n",
      "14/14 - 0s - loss: 0.0450 - accuracy: 0.9977\n",
      "Epoch 143/1000\n",
      "14/14 - 0s - loss: 0.0445 - accuracy: 0.9977\n",
      "Epoch 144/1000\n",
      "14/14 - 0s - loss: 0.0433 - accuracy: 0.9977\n",
      "Epoch 145/1000\n",
      "14/14 - 0s - loss: 0.0427 - accuracy: 0.9977\n",
      "Epoch 146/1000\n",
      "14/14 - 0s - loss: 0.0420 - accuracy: 0.9977\n",
      "Epoch 147/1000\n",
      "14/14 - 0s - loss: 0.0411 - accuracy: 0.9977\n",
      "Epoch 148/1000\n",
      "14/14 - 0s - loss: 0.0405 - accuracy: 0.9977\n",
      "Epoch 149/1000\n",
      "14/14 - 0s - loss: 0.0397 - accuracy: 0.9977\n",
      "Epoch 150/1000\n",
      "14/14 - 0s - loss: 0.0392 - accuracy: 0.9977\n",
      "Epoch 151/1000\n",
      "14/14 - 0s - loss: 0.0386 - accuracy: 0.9977\n",
      "Epoch 152/1000\n",
      "14/14 - 0s - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "14/14 - 0s - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "14/14 - 0s - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "14/14 - 0s - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "14/14 - 0s - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "14/14 - 0s - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "14/14 - 0s - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "14/14 - 0s - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "14/14 - 0s - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "14/14 - 0s - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "14/14 - 0s - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "14/14 - 0s - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "14/14 - 0s - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "14/14 - 0s - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "14/14 - 0s - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "14/14 - 0s - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "14/14 - 0s - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "14/14 - 0s - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "14/14 - 0s - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "14/14 - 0s - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "14/14 - 0s - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "14/14 - 0s - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "14/14 - 0s - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "14/14 - 0s - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "14/14 - 0s - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "14/14 - 0s - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "14/14 - 0s - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "14/14 - 0s - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "14/14 - 0s - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "14/14 - 0s - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "14/14 - 0s - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "14/14 - 0s - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "14/14 - 0s - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "14/14 - 0s - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "14/14 - 0s - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "14/14 - 0s - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "14/14 - 0s - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "14/14 - 0s - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "14/14 - 0s - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "14/14 - 0s - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "14/14 - 0s - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "14/14 - 0s - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "14/14 - 0s - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "14/14 - 0s - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "14/14 - 0s - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "14/14 - 0s - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "14/14 - 0s - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "14/14 - 0s - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "14/14 - 0s - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "14/14 - 0s - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "14/14 - 0s - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "14/14 - 0s - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "14/14 - 0s - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "14/14 - 0s - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "14/14 - 0s - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "14/14 - 0s - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "14/14 - 0s - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "14/14 - 0s - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "14/14 - 0s - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "14/14 - 0s - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "14/14 - 0s - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "14/14 - 0s - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "14/14 - 0s - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "14/14 - 0s - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "14/14 - 0s - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "14/14 - 0s - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "14/14 - 0s - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "14/14 - 0s - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "14/14 - 0s - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "14/14 - 0s - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "14/14 - 0s - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "14/14 - 0s - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "14/14 - 0s - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "14/14 - 0s - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "14/14 - 0s - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "14/14 - 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "14/14 - 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "14/14 - 0s - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "14/14 - 0s - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "14/14 - 0s - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "14/14 - 0s - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "14/14 - 0s - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "14/14 - 0s - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "14/14 - 0s - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "14/14 - 0s - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "14/14 - 0s - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "14/14 - 0s - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "14/14 - 0s - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "14/14 - 0s - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "14/14 - 0s - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "14/14 - 0s - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "14/14 - 0s - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "14/14 - 0s - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "14/14 - 0s - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "14/14 - 0s - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "14/14 - 0s - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "14/14 - 0s - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "14/14 - 0s - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "14/14 - 0s - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "14/14 - 0s - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "14/14 - 0s - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "14/14 - 0s - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "14/14 - 0s - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "14/14 - 0s - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "14/14 - 0s - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "14/14 - 0s - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "14/14 - 0s - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "14/14 - 0s - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "14/14 - 0s - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "14/14 - 0s - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "14/14 - 0s - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "14/14 - 0s - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "14/14 - 0s - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "14/14 - 0s - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "14/14 - 0s - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "14/14 - 0s - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "14/14 - 0s - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "14/14 - 0s - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "14/14 - 0s - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "14/14 - 0s - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "14/14 - 0s - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "14/14 - 0s - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "14/14 - 0s - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "14/14 - 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "14/14 - 0s - loss: 0.0097 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000\n",
      "14/14 - 0s - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "14/14 - 0s - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "14/14 - 0s - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "14/14 - 0s - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "14/14 - 0s - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "14/14 - 0s - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "14/14 - 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "14/14 - 0s - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "14/14 - 0s - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "14/14 - 0s - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "14/14 - 0s - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "14/14 - 0s - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "14/14 - 0s - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "14/14 - 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "14/14 - 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "14/14 - 0s - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "14/14 - 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "14/14 - 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "14/14 - 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "14/14 - 0s - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "14/14 - 0s - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "14/14 - 0s - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "14/14 - 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "14/14 - 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "14/14 - 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "14/14 - 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "14/14 - 0s - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "14/14 - 0s - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "14/14 - 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "14/14 - 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "14/14 - 0s - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "14/14 - 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "14/14 - 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "14/14 - 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "14/14 - 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "14/14 - 0s - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "14/14 - 0s - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "14/14 - 0s - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "14/14 - 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "14/14 - 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "14/14 - 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "14/14 - 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "14/14 - 0s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "14/14 - 0s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "14/14 - 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "14/14 - 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "14/14 - 0s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "14/14 - 0s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "14/14 - 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "14/14 - 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "14/14 - 0s - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "14/14 - 0s - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "14/14 - 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "14/14 - 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "14/14 - 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "14/14 - 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "14/14 - 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "14/14 - 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "14/14 - 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "14/14 - 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "14/14 - 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "14/14 - 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "14/14 - 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "14/14 - 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "14/14 - 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "14/14 - 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "14/14 - 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "14/14 - 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "14/14 - 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "14/14 - 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "14/14 - 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "14/14 - 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "14/14 - 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "14/14 - 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "14/14 - 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "14/14 - 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "14/14 - 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "14/14 - 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "14/14 - 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "14/14 - 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "14/14 - 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "14/14 - 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "14/14 - 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "14/14 - 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "14/14 - 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "14/14 - 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "14/14 - 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "14/14 - 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "14/14 - 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "14/14 - 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "14/14 - 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "14/14 - 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "14/14 - 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "14/14 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "14/14 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "14/14 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "14/14 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "14/14 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "14/14 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "14/14 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "14/14 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "14/14 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "14/14 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "14/14 - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "14/14 - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "14/14 - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "14/14 - 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "14/14 - 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "14/14 - 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "14/14 - 0s - loss: 9.9384e-04 - accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "14/14 - 0s - loss: 9.8681e-04 - accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "14/14 - 0s - loss: 9.8018e-04 - accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "14/14 - 0s - loss: 9.7360e-04 - accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "14/14 - 0s - loss: 9.6690e-04 - accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "14/14 - 0s - loss: 9.6017e-04 - accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "14/14 - 0s - loss: 9.5384e-04 - accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "14/14 - 0s - loss: 9.4728e-04 - accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "14/14 - 0s - loss: 9.4081e-04 - accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "14/14 - 0s - loss: 9.3456e-04 - accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "14/14 - 0s - loss: 9.2830e-04 - accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "14/14 - 0s - loss: 9.2173e-04 - accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "14/14 - 0s - loss: 9.1539e-04 - accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "14/14 - 0s - loss: 9.0883e-04 - accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "14/14 - 0s - loss: 9.0326e-04 - accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "14/14 - 0s - loss: 8.9678e-04 - accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "14/14 - 0s - loss: 8.9062e-04 - accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "14/14 - 0s - loss: 8.8454e-04 - accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "14/14 - 0s - loss: 8.7864e-04 - accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "14/14 - 0s - loss: 8.7278e-04 - accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "14/14 - 0s - loss: 8.6688e-04 - accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "14/14 - 0s - loss: 8.6090e-04 - accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "14/14 - 0s - loss: 8.5519e-04 - accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "14/14 - 0s - loss: 8.4961e-04 - accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "14/14 - 0s - loss: 8.4390e-04 - accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "14/14 - 0s - loss: 8.3820e-04 - accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "14/14 - 0s - loss: 8.3247e-04 - accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "14/14 - 0s - loss: 8.2689e-04 - accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "14/14 - 0s - loss: 8.2144e-04 - accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "14/14 - 0s - loss: 8.1594e-04 - accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "14/14 - 0s - loss: 8.1037e-04 - accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "14/14 - 0s - loss: 8.0501e-04 - accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "14/14 - 0s - loss: 7.9969e-04 - accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "14/14 - 0s - loss: 7.9429e-04 - accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "14/14 - 0s - loss: 7.8907e-04 - accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "14/14 - 0s - loss: 7.8390e-04 - accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "14/14 - 0s - loss: 7.7845e-04 - accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "14/14 - 0s - loss: 7.7310e-04 - accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "14/14 - 0s - loss: 7.6763e-04 - accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "14/14 - 0s - loss: 7.6279e-04 - accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "14/14 - 0s - loss: 7.5753e-04 - accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "14/14 - 0s - loss: 7.5236e-04 - accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "14/14 - 0s - loss: 7.4735e-04 - accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "14/14 - 0s - loss: 7.4227e-04 - accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "14/14 - 0s - loss: 7.3729e-04 - accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "14/14 - 0s - loss: 7.3233e-04 - accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "14/14 - 0s - loss: 7.2737e-04 - accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "14/14 - 0s - loss: 7.2259e-04 - accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "14/14 - 0s - loss: 7.1774e-04 - accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "14/14 - 0s - loss: 7.1284e-04 - accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "14/14 - 0s - loss: 7.0800e-04 - accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "14/14 - 0s - loss: 7.0328e-04 - accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "14/14 - 0s - loss: 6.9833e-04 - accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "14/14 - 0s - loss: 6.9354e-04 - accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "14/14 - 0s - loss: 6.8912e-04 - accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "14/14 - 0s - loss: 6.8444e-04 - accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "14/14 - 0s - loss: 6.7975e-04 - accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "14/14 - 0s - loss: 6.7526e-04 - accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "14/14 - 0s - loss: 6.7074e-04 - accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "14/14 - 0s - loss: 6.6594e-04 - accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "14/14 - 0s - loss: 6.6154e-04 - accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "14/14 - 0s - loss: 6.5699e-04 - accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "14/14 - 0s - loss: 6.5260e-04 - accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "14/14 - 0s - loss: 6.4812e-04 - accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "14/14 - 0s - loss: 6.4377e-04 - accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "14/14 - 0s - loss: 6.3930e-04 - accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "14/14 - 0s - loss: 6.3507e-04 - accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "14/14 - 0s - loss: 6.3064e-04 - accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "14/14 - 0s - loss: 6.2654e-04 - accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "14/14 - 0s - loss: 6.2226e-04 - accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "14/14 - 0s - loss: 6.1811e-04 - accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "14/14 - 0s - loss: 6.1396e-04 - accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "14/14 - 0s - loss: 6.0975e-04 - accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "14/14 - 0s - loss: 6.0566e-04 - accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "14/14 - 0s - loss: 6.0161e-04 - accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "14/14 - 0s - loss: 5.9772e-04 - accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "14/14 - 0s - loss: 5.9358e-04 - accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "14/14 - 0s - loss: 5.8964e-04 - accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "14/14 - 0s - loss: 5.8567e-04 - accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "14/14 - 0s - loss: 5.8180e-04 - accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "14/14 - 0s - loss: 5.7778e-04 - accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "14/14 - 0s - loss: 5.7393e-04 - accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "14/14 - 0s - loss: 5.7018e-04 - accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "14/14 - 0s - loss: 5.6629e-04 - accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "14/14 - 0s - loss: 5.6243e-04 - accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "14/14 - 0s - loss: 5.5872e-04 - accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "14/14 - 0s - loss: 5.5503e-04 - accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "14/14 - 0s - loss: 5.5125e-04 - accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "14/14 - 0s - loss: 5.4761e-04 - accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "14/14 - 0s - loss: 5.4382e-04 - accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "14/14 - 0s - loss: 5.4024e-04 - accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "14/14 - 0s - loss: 5.3642e-04 - accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "14/14 - 0s - loss: 5.3291e-04 - accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "14/14 - 0s - loss: 5.2929e-04 - accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "14/14 - 0s - loss: 5.2573e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1000\n",
      "14/14 - 0s - loss: 5.2216e-04 - accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "14/14 - 0s - loss: 5.1852e-04 - accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "14/14 - 0s - loss: 5.1522e-04 - accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "14/14 - 0s - loss: 5.1190e-04 - accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "14/14 - 0s - loss: 5.0850e-04 - accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "14/14 - 0s - loss: 5.0489e-04 - accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "14/14 - 0s - loss: 5.0156e-04 - accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "14/14 - 0s - loss: 4.9815e-04 - accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "14/14 - 0s - loss: 4.9517e-04 - accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "14/14 - 0s - loss: 4.9178e-04 - accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "14/14 - 0s - loss: 4.8852e-04 - accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "14/14 - 0s - loss: 4.8512e-04 - accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "14/14 - 0s - loss: 4.8178e-04 - accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "14/14 - 0s - loss: 4.7844e-04 - accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "14/14 - 0s - loss: 4.7526e-04 - accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "14/14 - 0s - loss: 4.7213e-04 - accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "14/14 - 0s - loss: 4.6900e-04 - accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "14/14 - 0s - loss: 4.6589e-04 - accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "14/14 - 0s - loss: 4.6293e-04 - accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "14/14 - 0s - loss: 4.5987e-04 - accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "14/14 - 0s - loss: 4.5688e-04 - accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "14/14 - 0s - loss: 4.5377e-04 - accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "14/14 - 0s - loss: 4.5065e-04 - accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "14/14 - 0s - loss: 4.4756e-04 - accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "14/14 - 0s - loss: 4.4454e-04 - accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "14/14 - 0s - loss: 4.4166e-04 - accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "14/14 - 0s - loss: 4.3861e-04 - accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "14/14 - 0s - loss: 4.3554e-04 - accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "14/14 - 0s - loss: 4.3247e-04 - accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "14/14 - 0s - loss: 4.2949e-04 - accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "14/14 - 0s - loss: 4.2677e-04 - accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "14/14 - 0s - loss: 4.2402e-04 - accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "14/14 - 0s - loss: 4.2121e-04 - accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "14/14 - 0s - loss: 4.1831e-04 - accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "14/14 - 0s - loss: 4.1551e-04 - accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "14/14 - 0s - loss: 4.1279e-04 - accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "14/14 - 0s - loss: 4.0994e-04 - accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "14/14 - 0s - loss: 4.0729e-04 - accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "14/14 - 0s - loss: 4.0447e-04 - accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "14/14 - 0s - loss: 4.0181e-04 - accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "14/14 - 0s - loss: 3.9922e-04 - accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "14/14 - 0s - loss: 3.9688e-04 - accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "14/14 - 0s - loss: 3.9408e-04 - accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "14/14 - 0s - loss: 3.9148e-04 - accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "14/14 - 0s - loss: 3.8890e-04 - accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "14/14 - 0s - loss: 3.8627e-04 - accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "14/14 - 0s - loss: 3.8366e-04 - accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "14/14 - 0s - loss: 3.8112e-04 - accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "14/14 - 0s - loss: 3.7863e-04 - accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "14/14 - 0s - loss: 3.7609e-04 - accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "14/14 - 0s - loss: 3.7348e-04 - accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "14/14 - 0s - loss: 3.7114e-04 - accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "14/14 - 0s - loss: 3.6864e-04 - accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "14/14 - 0s - loss: 3.6610e-04 - accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "14/14 - 0s - loss: 3.6367e-04 - accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "14/14 - 0s - loss: 3.6118e-04 - accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "14/14 - 0s - loss: 3.5887e-04 - accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "14/14 - 0s - loss: 3.5655e-04 - accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "14/14 - 0s - loss: 3.5419e-04 - accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "14/14 - 0s - loss: 3.5183e-04 - accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "14/14 - 0s - loss: 3.4948e-04 - accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "14/14 - 0s - loss: 3.4721e-04 - accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "14/14 - 0s - loss: 3.4501e-04 - accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "14/14 - 0s - loss: 3.4263e-04 - accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "14/14 - 0s - loss: 3.4038e-04 - accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "14/14 - 0s - loss: 3.3819e-04 - accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "14/14 - 0s - loss: 3.3581e-04 - accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "14/14 - 0s - loss: 3.3359e-04 - accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "14/14 - 0s - loss: 3.3139e-04 - accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "14/14 - 0s - loss: 3.2922e-04 - accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "14/14 - 0s - loss: 3.2701e-04 - accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "14/14 - 0s - loss: 3.2479e-04 - accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "14/14 - 0s - loss: 3.2270e-04 - accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "14/14 - 0s - loss: 3.2052e-04 - accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "14/14 - 0s - loss: 3.1842e-04 - accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "14/14 - 0s - loss: 3.1624e-04 - accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "14/14 - 0s - loss: 3.1415e-04 - accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "14/14 - 0s - loss: 3.1196e-04 - accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "14/14 - 0s - loss: 3.0995e-04 - accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "14/14 - 0s - loss: 3.0791e-04 - accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "14/14 - 0s - loss: 3.0593e-04 - accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "14/14 - 0s - loss: 3.0392e-04 - accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "14/14 - 0s - loss: 3.0193e-04 - accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "14/14 - 0s - loss: 2.9994e-04 - accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "14/14 - 0s - loss: 2.9794e-04 - accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "14/14 - 0s - loss: 2.9601e-04 - accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "14/14 - 0s - loss: 2.9403e-04 - accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "14/14 - 0s - loss: 2.9210e-04 - accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "14/14 - 0s - loss: 2.9016e-04 - accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "14/14 - 0s - loss: 2.8823e-04 - accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "14/14 - 0s - loss: 2.8650e-04 - accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "14/14 - 0s - loss: 2.8452e-04 - accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "14/14 - 0s - loss: 2.8261e-04 - accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "14/14 - 0s - loss: 2.8066e-04 - accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "14/14 - 0s - loss: 2.7880e-04 - accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "14/14 - 0s - loss: 2.7697e-04 - accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "14/14 - 0s - loss: 2.7523e-04 - accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "14/14 - 0s - loss: 2.7331e-04 - accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "14/14 - 0s - loss: 2.7159e-04 - accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "14/14 - 0s - loss: 2.6980e-04 - accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "14/14 - 0s - loss: 2.6801e-04 - accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "14/14 - 0s - loss: 2.6618e-04 - accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "14/14 - 0s - loss: 2.6442e-04 - accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "14/14 - 0s - loss: 2.6269e-04 - accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "14/14 - 0s - loss: 2.6096e-04 - accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "14/14 - 0s - loss: 2.5924e-04 - accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "14/14 - 0s - loss: 2.5765e-04 - accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "14/14 - 0s - loss: 2.5589e-04 - accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "14/14 - 0s - loss: 2.5420e-04 - accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "14/14 - 0s - loss: 2.5256e-04 - accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "14/14 - 0s - loss: 2.5085e-04 - accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "14/14 - 0s - loss: 2.4934e-04 - accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "14/14 - 0s - loss: 2.4757e-04 - accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "14/14 - 0s - loss: 2.4595e-04 - accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "14/14 - 0s - loss: 2.4438e-04 - accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "14/14 - 0s - loss: 2.4274e-04 - accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "14/14 - 0s - loss: 2.4113e-04 - accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "14/14 - 0s - loss: 2.3955e-04 - accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "14/14 - 0s - loss: 2.3791e-04 - accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "14/14 - 0s - loss: 2.3634e-04 - accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "14/14 - 0s - loss: 2.3478e-04 - accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "14/14 - 0s - loss: 2.3323e-04 - accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "14/14 - 0s - loss: 2.3169e-04 - accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "14/14 - 0s - loss: 2.3012e-04 - accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "14/14 - 0s - loss: 2.2860e-04 - accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "14/14 - 0s - loss: 2.2705e-04 - accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "14/14 - 0s - loss: 2.2556e-04 - accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "14/14 - 0s - loss: 2.2403e-04 - accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "14/14 - 0s - loss: 2.2258e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "14/14 - 0s - loss: 2.2119e-04 - accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "14/14 - 0s - loss: 2.1974e-04 - accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "14/14 - 0s - loss: 2.1821e-04 - accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "14/14 - 0s - loss: 2.1675e-04 - accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "14/14 - 0s - loss: 2.1529e-04 - accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "14/14 - 0s - loss: 2.1379e-04 - accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "14/14 - 0s - loss: 2.1239e-04 - accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "14/14 - 0s - loss: 2.1095e-04 - accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "14/14 - 0s - loss: 2.0953e-04 - accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "14/14 - 0s - loss: 2.0815e-04 - accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "14/14 - 0s - loss: 2.0673e-04 - accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "14/14 - 0s - loss: 2.0538e-04 - accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "14/14 - 0s - loss: 2.0402e-04 - accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "14/14 - 0s - loss: 2.0269e-04 - accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "14/14 - 0s - loss: 2.0139e-04 - accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "14/14 - 0s - loss: 2.0007e-04 - accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "14/14 - 0s - loss: 1.9879e-04 - accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "14/14 - 0s - loss: 1.9745e-04 - accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "14/14 - 0s - loss: 1.9617e-04 - accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "14/14 - 0s - loss: 1.9487e-04 - accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "14/14 - 0s - loss: 1.9357e-04 - accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "14/14 - 0s - loss: 1.9225e-04 - accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "14/14 - 0s - loss: 1.9101e-04 - accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "14/14 - 0s - loss: 1.8974e-04 - accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "14/14 - 0s - loss: 1.8850e-04 - accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "14/14 - 0s - loss: 1.8722e-04 - accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "14/14 - 0s - loss: 1.8601e-04 - accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "14/14 - 0s - loss: 1.8477e-04 - accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "14/14 - 0s - loss: 1.8357e-04 - accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "14/14 - 0s - loss: 1.8244e-04 - accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "14/14 - 0s - loss: 1.8113e-04 - accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "14/14 - 0s - loss: 1.8000e-04 - accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "14/14 - 0s - loss: 1.7876e-04 - accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "14/14 - 0s - loss: 1.7759e-04 - accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "14/14 - 0s - loss: 1.7645e-04 - accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "14/14 - 0s - loss: 1.7524e-04 - accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "14/14 - 0s - loss: 1.7407e-04 - accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "14/14 - 0s - loss: 1.7299e-04 - accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "14/14 - 0s - loss: 1.7183e-04 - accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "14/14 - 0s - loss: 1.7070e-04 - accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "14/14 - 0s - loss: 1.6957e-04 - accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "14/14 - 0s - loss: 1.6850e-04 - accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "14/14 - 0s - loss: 1.6738e-04 - accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "14/14 - 0s - loss: 1.6631e-04 - accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "14/14 - 0s - loss: 1.6522e-04 - accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "14/14 - 0s - loss: 1.6411e-04 - accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "14/14 - 0s - loss: 1.6310e-04 - accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "14/14 - 0s - loss: 1.6198e-04 - accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "14/14 - 0s - loss: 1.6097e-04 - accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "14/14 - 0s - loss: 1.5989e-04 - accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "14/14 - 0s - loss: 1.5884e-04 - accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "14/14 - 0s - loss: 1.5779e-04 - accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "14/14 - 0s - loss: 1.5674e-04 - accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "14/14 - 0s - loss: 1.5571e-04 - accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "14/14 - 0s - loss: 1.5469e-04 - accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "14/14 - 0s - loss: 1.5366e-04 - accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "14/14 - 0s - loss: 1.5274e-04 - accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "14/14 - 0s - loss: 1.5170e-04 - accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "14/14 - 0s - loss: 1.5072e-04 - accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "14/14 - 0s - loss: 1.4971e-04 - accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "14/14 - 0s - loss: 1.4870e-04 - accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "14/14 - 0s - loss: 1.4773e-04 - accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "14/14 - 0s - loss: 1.4671e-04 - accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "14/14 - 0s - loss: 1.4576e-04 - accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "14/14 - 0s - loss: 1.4476e-04 - accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "14/14 - 0s - loss: 1.4382e-04 - accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "14/14 - 0s - loss: 1.4289e-04 - accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "14/14 - 0s - loss: 1.4188e-04 - accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "14/14 - 0s - loss: 1.4096e-04 - accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "14/14 - 0s - loss: 1.4003e-04 - accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "14/14 - 0s - loss: 1.3909e-04 - accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "14/14 - 0s - loss: 1.3814e-04 - accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "14/14 - 0s - loss: 1.3722e-04 - accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "14/14 - 0s - loss: 1.3633e-04 - accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "14/14 - 0s - loss: 1.3539e-04 - accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "14/14 - 0s - loss: 1.3453e-04 - accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "14/14 - 0s - loss: 1.3359e-04 - accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "14/14 - 0s - loss: 1.3270e-04 - accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "14/14 - 0s - loss: 1.3183e-04 - accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "14/14 - 0s - loss: 1.3094e-04 - accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "14/14 - 0s - loss: 1.3010e-04 - accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "14/14 - 0s - loss: 1.2927e-04 - accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "14/14 - 0s - loss: 1.2840e-04 - accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "14/14 - 0s - loss: 1.2758e-04 - accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "14/14 - 0s - loss: 1.2674e-04 - accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "14/14 - 0s - loss: 1.2589e-04 - accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "14/14 - 0s - loss: 1.2504e-04 - accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "14/14 - 0s - loss: 1.2419e-04 - accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "14/14 - 0s - loss: 1.2335e-04 - accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "14/14 - 0s - loss: 1.2251e-04 - accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "14/14 - 0s - loss: 1.2172e-04 - accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "14/14 - 0s - loss: 1.2089e-04 - accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "14/14 - 0s - loss: 1.2012e-04 - accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "14/14 - 0s - loss: 1.1931e-04 - accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "14/14 - 0s - loss: 1.1852e-04 - accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "14/14 - 0s - loss: 1.1774e-04 - accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "14/14 - 0s - loss: 1.1697e-04 - accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "14/14 - 0s - loss: 1.1637e-04 - accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "14/14 - 0s - loss: 1.1559e-04 - accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "14/14 - 0s - loss: 1.1481e-04 - accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "14/14 - 0s - loss: 1.1401e-04 - accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "14/14 - 0s - loss: 1.1325e-04 - accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "14/14 - 0s - loss: 1.1250e-04 - accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "14/14 - 0s - loss: 1.1175e-04 - accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "14/14 - 0s - loss: 1.1099e-04 - accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "14/14 - 0s - loss: 1.1026e-04 - accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "14/14 - 0s - loss: 1.0951e-04 - accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "14/14 - 0s - loss: 1.0887e-04 - accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "14/14 - 0s - loss: 1.0808e-04 - accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "14/14 - 0s - loss: 1.0736e-04 - accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "14/14 - 0s - loss: 1.0663e-04 - accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "14/14 - 0s - loss: 1.0590e-04 - accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "14/14 - 0s - loss: 1.0516e-04 - accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "14/14 - 0s - loss: 1.0445e-04 - accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "14/14 - 0s - loss: 1.0375e-04 - accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "14/14 - 0s - loss: 1.0304e-04 - accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "14/14 - 0s - loss: 1.0238e-04 - accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "14/14 - 0s - loss: 1.0170e-04 - accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "14/14 - 0s - loss: 1.0102e-04 - accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "14/14 - 0s - loss: 1.0034e-04 - accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "14/14 - 0s - loss: 9.9690e-05 - accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "14/14 - 0s - loss: 9.9044e-05 - accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "14/14 - 0s - loss: 9.8395e-05 - accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "14/14 - 0s - loss: 9.7724e-05 - accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "14/14 - 0s - loss: 9.7091e-05 - accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "14/14 - 0s - loss: 9.6454e-05 - accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "14/14 - 0s - loss: 9.5837e-05 - accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "14/14 - 0s - loss: 9.5195e-05 - accuracy: 1.0000\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 0s - loss: 9.4574e-05 - accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "14/14 - 0s - loss: 9.3966e-05 - accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "14/14 - 0s - loss: 9.3361e-05 - accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "14/14 - 0s - loss: 9.2752e-05 - accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "14/14 - 0s - loss: 9.2148e-05 - accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "14/14 - 0s - loss: 9.1531e-05 - accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "14/14 - 0s - loss: 9.0935e-05 - accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "14/14 - 0s - loss: 9.0345e-05 - accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "14/14 - 0s - loss: 8.9768e-05 - accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "14/14 - 0s - loss: 8.9174e-05 - accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "14/14 - 0s - loss: 8.8625e-05 - accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "14/14 - 0s - loss: 8.8026e-05 - accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "14/14 - 0s - loss: 8.7463e-05 - accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "14/14 - 0s - loss: 8.6888e-05 - accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "14/14 - 0s - loss: 8.6325e-05 - accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "14/14 - 0s - loss: 8.5762e-05 - accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "14/14 - 0s - loss: 8.5159e-05 - accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "14/14 - 0s - loss: 8.4626e-05 - accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "14/14 - 0s - loss: 8.4049e-05 - accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "14/14 - 0s - loss: 8.3492e-05 - accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "14/14 - 0s - loss: 8.2948e-05 - accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "14/14 - 0s - loss: 8.2404e-05 - accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "14/14 - 0s - loss: 8.1865e-05 - accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "14/14 - 0s - loss: 8.1307e-05 - accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "14/14 - 0s - loss: 8.0811e-05 - accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "14/14 - 0s - loss: 8.0270e-05 - accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "14/14 - 0s - loss: 7.9754e-05 - accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "14/14 - 0s - loss: 7.9221e-05 - accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "14/14 - 0s - loss: 7.8667e-05 - accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "14/14 - 0s - loss: 7.8155e-05 - accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "14/14 - 0s - loss: 7.7617e-05 - accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "14/14 - 0s - loss: 7.7099e-05 - accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "14/14 - 0s - loss: 7.6577e-05 - accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "14/14 - 0s - loss: 7.6088e-05 - accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "14/14 - 0s - loss: 7.5587e-05 - accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "14/14 - 0s - loss: 7.5107e-05 - accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "14/14 - 0s - loss: 7.4632e-05 - accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "14/14 - 0s - loss: 7.4118e-05 - accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "14/14 - 0s - loss: 7.3629e-05 - accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "14/14 - 0s - loss: 7.3124e-05 - accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "14/14 - 0s - loss: 7.2649e-05 - accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "14/14 - 0s - loss: 7.2156e-05 - accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "14/14 - 0s - loss: 7.1686e-05 - accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "14/14 - 0s - loss: 7.1230e-05 - accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "14/14 - 0s - loss: 7.0755e-05 - accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "14/14 - 0s - loss: 7.0274e-05 - accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "14/14 - 0s - loss: 6.9835e-05 - accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "14/14 - 0s - loss: 6.9346e-05 - accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "14/14 - 0s - loss: 6.8902e-05 - accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "14/14 - 0s - loss: 6.8441e-05 - accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "14/14 - 0s - loss: 6.7979e-05 - accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "14/14 - 0s - loss: 6.7535e-05 - accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "14/14 - 0s - loss: 6.7074e-05 - accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "14/14 - 0s - loss: 6.6667e-05 - accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "14/14 - 0s - loss: 6.6204e-05 - accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "14/14 - 0s - loss: 6.5797e-05 - accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "14/14 - 0s - loss: 6.5377e-05 - accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "14/14 - 0s - loss: 6.4957e-05 - accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "14/14 - 0s - loss: 6.4531e-05 - accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "14/14 - 0s - loss: 6.4095e-05 - accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "14/14 - 0s - loss: 6.3681e-05 - accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "14/14 - 0s - loss: 6.3251e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a7962e6f10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 1.5976 - accuracy: 0.9580\n",
      "Loss: 1.597614049911499, Accuracy: 0.9580419659614563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
